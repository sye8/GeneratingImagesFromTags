{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argostranslate import package, translate\n",
    "#package.install_from_path('translate-ja_en-1_1.argosmodel')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "installed_languages=translate.load_installed_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English', 'Japanese']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[str(lang) for lang in installed_languages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_en_es = installed_languages[1].get_translation(installed_languages[0])\n",
    "translation_en_es.translate(\"こんにちは\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=json.loads(Path('../PIXIV/valid_img.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "class JapaneseTokenizer:\n",
    "    def __init__(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "    def decode(self, tokens, pad_tokens = {}):\n",
    "        if torch.is_tensor(tokens):\n",
    "            tokens = tokens.tolist()\n",
    "            \n",
    "        ignore_ids = pad_tokens.union({0})\n",
    "        tokens = [token for token in tokens if token not in ignore_ids]\n",
    "        return self.tokenizer.decode(tokens)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return torch.tensor(self.tokenizer.encode(text, add_special_tokens = False))\n",
    "\n",
    "    def tokenize(self, texts, context_length = 256, truncate_text = False):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        all_tokens = [self.encode(text) for text in texts]\n",
    "\n",
    "        result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "        for i, tokens in enumerate(all_tokens):\n",
    "            if len(tokens) > context_length:\n",
    "                if truncate_text:\n",
    "                    tokens = tokens[:context_length]\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
    "            result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18762, 28888,  6332])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jt=JapaneseTokenizer()\n",
    "t=jt.encode('こんにちは')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jt.decode(t,{0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_list={}\n",
    "for i in db:\n",
    "    if i[1]>100:\n",
    "        jj=[str(i[1]),*i[3]]\n",
    "        for j in jj:\n",
    "            for k in jj:\n",
    "                if (k == j):\n",
    "                    continue\n",
    "                elif (j in k):\n",
    "                    try:\n",
    "                        jj.remove(j)\n",
    "                    except ValueError as e:\n",
    "                        break\n",
    "                elif (k in j):\n",
    "                    try:\n",
    "                        jj.remove(k)\n",
    "                    except ValueError as e:\n",
    "                        break\n",
    "        t=' '.join(jj)\n",
    "        top_list[Path(i[2]).name]=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168629"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_list.keys():\n",
    "    top_pixiv=Path('../TOP_PIXIV')\n",
    "    all_pixiv=Path('../PIXIV/img_clean')\n",
    "    (top_pixiv/i).write_bytes((all_pixiv/i).read_bytes())\n",
    "    (top_pixiv/Path(i).with_suffix('.txt')).write_text(top_list[i], encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d88d0f0922b831295e6026ea35fb67de54c011a73b2adcce271dbe4e7416a607"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
